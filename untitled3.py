# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ynO1nkhz48Gxqf8c25rYl1WNXr6mBuwu
"""

import pandas as pd

# File paths
file1 = "/content/live_overflow_videos.csv"
file2 = "/content/neso_academy_transcripts.csv"

# Load the datasets
df1 = pd.read_csv(file1)
df2 = pd.read_csv(file2)

# Display column names
print("Columns in live_overflow_videos.csv:")
print(df1.columns.tolist(), "\n")

print("Columns in neso_academy_transcripts.csv:")
print(df2.columns.tolist(), "\n")

# Remove empty rows
df1_cleaned = df1.dropna(how='all')
df2_cleaned = df2.dropna(how='all')

# Save cleaned files
output1 = "/content/live_overflow_videos_no_empty_rows.csv"
output2 = "/content/neso_academy_no_empty_rowstranscripts.csv"

df1_cleaned.to_csv(output1, index=False)
df2_cleaned.to_csv(output2, index=False)

print("Saved cleaned files:")
print(output1)
print(output2)

import pandas as pd

# Load your dataset
file_path = "/content/live_overflow_videos_no_empty_rows.csv"
df = pd.read_csv(file_path)

# Function to convert ISO 8601 duration format (PT1H2M30S → seconds)
def parse_duration_to_seconds(duration_str):
    if pd.isna(duration_str):
        return 0

    duration_str = str(duration_str)

    # Remove PT prefix if present
    if duration_str.startswith('PT'):
        duration_str = duration_str[2:]

    hours = minutes = seconds = 0

    # Extract hour component
    if 'H' in duration_str:
        hours = int(duration_str.split('H')[0])
        duration_str = duration_str.split('H')[1]

    # Extract minute component
    if 'M' in duration_str:
        minutes = int(duration_str.split('M')[0])
        duration_str = duration_str.split('M')[1]

    # Extract seconds component
    if 'S' in duration_str:
        seconds = int(duration_str.split('S')[0])

    return hours * 3600 + minutes * 60 + seconds

# Apply conversion
df['duration_seconds'] = df['duration'].apply(parse_duration_to_seconds)

# Save updated file
output_file = "/content/live_overflow_videos_converted.csv"
df.to_csv(output_file, index=False)

print("Conversion completed! Saved to:", output_file)
print(df[['duration', 'duration_seconds']].head())

import pandas as pd

# Input file paths
videos_file = "/content/live_overflow_videos_converted.csv"
transcripts_file = "/content/neso_academy_no_empty_rowstranscripts.csv"

# Output file path
output_file = "/content/Neso_academy_compiled_data.csv"

# Load datasets
df_videos = pd.read_csv(videos_file)
df_transcripts = pd.read_csv(transcripts_file)

# Ensure required columns exist
if "id" not in df_videos.columns:
    raise ValueError("Column 'id' not found in live_overflow_videos_converted.csv")

if "id" not in df_transcripts.columns:
    raise ValueError("Column 'id' not found in neso_academy_no_empty_rowstranscripts.csv")

if "transcript" not in df_transcripts.columns:
    raise ValueError("Column 'transcript' not found in neso_academy_no_empty_rowstranscripts.csv")

# Use only id + transcript from transcripts file
df_transcripts = df_transcripts[["id", "transcript"]]

# Merge: keep all rows from videos, add transcript where available
merged_df = pd.merge(df_videos, df_transcripts, on="id", how="left")

# Create is_transcript_available column (yes / no)
def flag_transcript(x):
    if pd.isna(x) or str(x).strip() in ["", "nan", "NaN", "None"]:
        return "no"
    return "yes"

merged_df["is_transcript_available"] = merged_df["transcript"].apply(flag_transcript)

# Desired column order
desired_column_order = [
    "id",
    "title",
    "description",
    "publishedAt",
    "tags",
    "categoryId",
    "defaultLanguage",
    "defaultAudioLanguage",
    "thumbnail_default",
    "thumbnail_high",
    "duration",
    "viewCount",
    "likeCount",
    "commentCount",
    "privacyStatus",
    "channel_id",
    "channel_title",
    "channel_description",
    "channel_country",
    "channel_thumbnail",
    "channel_subscriberCount",
    "channel_videoCount",
    "is_transcript_available",
    "transcript",
    "duration_seconds",
]

# Keep only columns that actually exist, in the specified order
final_columns = [col for col in desired_column_order if col in merged_df.columns]

# Plus any extra columns (if present) at the end, without breaking
extra_columns = [col for col in merged_df.columns if col not in final_columns]
final_columns += extra_columns

merged_df = merged_df[final_columns]

# Save to CSV
merged_df.to_csv(output_file, index=False)

print("Merged file saved as", output_file)
print("Shape of merged data", merged_df.shape)
print(merged_df[["id", "duration", "duration_seconds", "is_transcript_available"]].head())

import pandas as pd

file_path = "/content/cleaned_youtube_data.csv"

df = pd.read_csv(file_path)

print("Total Columns:", len(df.columns))
print("\nColumn Names:\n")
for col in df.columns:
    print(col)

import pandas as pd

# File paths
file1 = "/content/Neso_academy_compiled_data.csv"
file2 = "/content/cleaned_youtube_data.csv"

# Output file path
output_file = "/content/mergedNeso_academy_compiled_data.csv"

# Load data
df1 = pd.read_csv(file1)
df2 = pd.read_csv(file2)

print("Rows in Neso_academy_compiled_data:", len(df1))
print("Rows in cleaned_youtube_data:", len(df2))

# Merge: df2 first to prioritize cleaned data in case of duplicates
merged_df = pd.concat([df2, df1], ignore_index=True)

# Remove duplicates based on id (keep first occurrence → cleaned data preferred)
before = len(merged_df)
merged_df = merged_df.drop_duplicates(subset="id", keep="first")
removed = before - len(merged_df)

print("Duplicate rows removed:", removed)
print("Final row count:", len(merged_df))

# Save merged dataset
merged_df.to_csv(output_file, index=False)

print("\nMerged dataset saved as:", output_file)
print("\nColumn names preserved:")
print(merged_df.columns.tolist())

# Display sample preview
print("\nSample:")
print(merged_df.head())

import pandas as pd

# Input file path
file_path = "/content/mergedNeso_academy_compiled_data.csv"

# Load dataset
df = pd.read_csv(file_path)

# Convert to Boolean TRUE/FALSE (uppercase text)
df["is_transcript_available"] = df["is_transcript_available"].apply(
    lambda x: "TRUE" if str(x).strip().lower() == "true" else "FALSE"
)

# Save updated dataset
output_file = "/content/MergedNeso_academy_compiled_data.csv"
df.to_csv(output_file, index=False)

print("Column updated successfully!")
print("Saved as:", output_file)

# Show a quick preview
print(df[["id", "is_transcript_available"]].head())

import pandas as pd
import re

# ==============================
#  Paths
# ==============================
input_file = "/content/MergedNeso_academy_compiled_data.csv"
output_file = "/content/Final_MergedNeso_academy_compiled_data.csv"

# ==============================
#  Helper functions
# ==============================

def clean_text(text):
    if pd.isna(text):
        return text
    text = str(text)
    text = re.sub(r'http\S+|www\S+|https\S+', '', text)  # Remove URLs
    text = re.sub(r"[^\w\s.,!?-]", "", text)  # Remove special chars
    text = re.sub(r"\s+", " ", text).strip()
    return text.lower()

def parse_duration_to_seconds(duration_str):
    if pd.isna(duration_str):
        return 0
    duration_str = str(duration_str).strip()
    if duration_str.isdigit():
        return int(duration_str)
    if duration_str.startswith("PT"):
        duration_str = duration_str[2:]
    h = m = s = 0
    if "H" in duration_str:
        part = duration_str.split("H")
        h = int(part[0]) if part[0] else 0
        duration_str = part[1]
    if "M" in duration_str:
        part = duration_str.split("M")
        m = int(part[0]) if part[0] else 0
        duration_str = part[1]
    if "S" in duration_str:
        part = duration_str.split("S")
        s = int(part[0]) if part[0] else 0
    return h * 3600 + m * 60 + s

# ==============================
#  Load data
# ==============================
df = pd.read_csv(input_file)
print("Initial shape:", df.shape)

# ==============================
# Clean title + transcript text
# ==============================
for col in ["title", "transcript"]:
    if col in df.columns:
        df[col] = df[col].apply(clean_text)

# ==============================
# Drop duplicate IDs
# ==============================
if "id" in df.columns:
    df.drop_duplicates(subset="id", keep="first", inplace=True)
    df.reset_index(drop=True, inplace=True)

# ==============================
# Ensure duration_seconds correct
# ==============================
if "duration" in df.columns:
    df["duration_seconds"] = df["duration"].apply(parse_duration_to_seconds)

# ==============================
# Convert is_transcript_available → TRUE/FALSE
# ==============================
def flag_transcript(x):
    return "TRUE" if isinstance(x, str) and x.strip() not in ["", "nan", "none"] else "FALSE"

if "transcript" in df.columns:
    df["is_transcript_available"] = df["transcript"].apply(flag_transcript)

# ==============================
#  Save final file
# ==============================
df.to_csv(output_file, index=False)
print("\nSaved cleaned + converted dataset to:", output_file)
print("\nFinal shape:", df.shape)
print(df.head()[["id", "is_transcript_available", "duration", "duration_seconds"]])